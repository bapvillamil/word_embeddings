{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b730fc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "# nltk.download('punkt')\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50167fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "      <th>category_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  category  \\\n",
       "0  when modi promised “minimum government maximum...        -1   \n",
       "1  talk all the nonsense and continue all the dra...         0   \n",
       "2  what did just say vote for modi  welcome bjp t...         1   \n",
       "3  asking his supporters prefix chowkidar their n...         1   \n",
       "4  answer who among these the most powerful world...         1   \n",
       "\n",
       "  category_sentiment  \n",
       "0           negative  \n",
       "1            neutral  \n",
       "2           positive  \n",
       "3           positive  \n",
       "4           positive  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Twitter.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3095c044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    72254\n",
       " 0    62713\n",
       "-1    43019\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.dropna()\n",
    "df['category'] = df['category'].astype(int)\n",
    "df = df.reset_index(drop=True)\n",
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de8d9e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    72254\n",
       " 0    62713\n",
       "-1    43019\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df=df[df['category']!=0]\n",
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe85e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CPORGALINAS\\AppData\\Local\\Temp\\ipykernel_26060\\490375356.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data=data.append(df[df['category']==0][:43019])\n",
      "C:\\Users\\CPORGALINAS\\AppData\\Local\\Temp\\ipykernel_26060\\490375356.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data=data.append(df[df['category']==1][:43019])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1    43019\n",
       " 0    43019\n",
       " 1    43019\n",
       "Name: category, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "      <th>category_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>since rahul gandhis only hope bring down naren...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>modi once called sonia jersey cow rahul her hy...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>least seven government school teachers have be...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'@MadShad31 Wow, thats kinda sad then  Bet it ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'Bens car broke down in the middle of nowhere....</td>\n",
       "      <td>-1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129052</th>\n",
       "      <td>right sir modi jee are great</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129053</th>\n",
       "      <td>sujrewala know whats your people calculations ...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129054</th>\n",
       "      <td>⁦\\r\\nrgkmkb mission shakti rahul gandhi says w...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129055</th>\n",
       "      <td>new post added mumbai press official site cong...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129056</th>\n",
       "      <td>high time elect the most important post the co...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129057 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean_text  category  \\\n",
       "0       since rahul gandhis only hope bring down naren...        -1   \n",
       "1       modi once called sonia jersey cow rahul her hy...        -1   \n",
       "2       least seven government school teachers have be...        -1   \n",
       "3       '@MadShad31 Wow, thats kinda sad then  Bet it ...        -1   \n",
       "4       'Bens car broke down in the middle of nowhere....        -1   \n",
       "...                                                   ...       ...   \n",
       "129052                      right sir modi jee are great          1   \n",
       "129053  sujrewala know whats your people calculations ...         1   \n",
       "129054  ⁦\\r\\nrgkmkb mission shakti rahul gandhi says w...         1   \n",
       "129055  new post added mumbai press official site cong...         1   \n",
       "129056  high time elect the most important post the co...         1   \n",
       "\n",
       "       category_sentiment  \n",
       "0                negative  \n",
       "1                negative  \n",
       "2                negative  \n",
       "3                negative  \n",
       "4                negative  \n",
       "...                   ...  \n",
       "129052           positive  \n",
       "129053           positive  \n",
       "129054           positive  \n",
       "129055           positive  \n",
       "129056           positive  \n",
       "\n",
       "[129057 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True) #shuffling of tweets\n",
    "data=df[df['category']==-1][:43019]\n",
    "data=data.append(df[df['category']==0][:43019])\n",
    "data=data.append(df[df['category']==1][:43019])\n",
    "data = data.reset_index(drop=True)\n",
    "display(data['category'].value_counts())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d052fa6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CPORGALINAS\\Documents\\Machine Learning\\Revalida 2\\env\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data['pre_process'] = data['clean_text'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
    "data['pre_process']=data['pre_process'].apply(lambda x: BeautifulSoup(x).get_text())\n",
    "data['pre_process']=data['pre_process'].apply(lambda x: re.sub(r\"http\\S+\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30c1c06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contractions(s):\n",
    "    s = re.sub(r\"won't\", \"will not\",s)\n",
    "    s = re.sub(r\"would't\", \"would not\",s)\n",
    "    s = re.sub(r\"could't\", \"could not\",s)\n",
    "    s = re.sub(r\"\\'d\", \" would\",s)\n",
    "    s = re.sub(r\"can\\'t\", \"can not\",s)\n",
    "    s = re.sub(r\"n\\'t\", \" not\", s)\n",
    "    s= re.sub(r\"\\'re\", \" are\", s)\n",
    "    s = re.sub(r\"\\'s\", \" is\", s)\n",
    "    s = re.sub(r\"\\'ll\", \" will\", s)\n",
    "    s = re.sub(r\"\\'t\", \" not\", s)\n",
    "    s = re.sub(r\"\\'ve\", \" have\", s)\n",
    "    s = re.sub(r\"\\'m\", \" am\", s)\n",
    "    return s\n",
    "data['pre_process']=data['pre_process'].apply(lambda x:contractions(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6f8ffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pre_process']=data['pre_process'].apply(lambda x: \" \".join([re.sub('[^A-Za-z]+','', x) for x in nltk.word_tokenize(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70dac8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "# stop = stopwords.words('english')\n",
    "# data['pre_process']=data['pre_process'].apply(lambda x: \" \".join([x for x in x.split() if x not in stop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b075e5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem import WordNetLemmatizer\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "# data['pre_process']=data['pre_process'].apply(lambda x: \" \".join([lemmatizer.lemmatize(w) for w in nltk.word_tokenize(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4b62ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "      <th>category_sentiment</th>\n",
       "      <th>pre_process</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>since rahul gandhis only hope bring down naren...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negative</td>\n",
       "      <td>since rahul gandhis only hope bring down naren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>modi once called sonia jersey cow rahul her hy...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negative</td>\n",
       "      <td>modi once called sonia jersey cow rahul her hy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>least seven government school teachers have be...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negative</td>\n",
       "      <td>least seven government school teachers have be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'@MadShad31 Wow, thats kinda sad then  Bet it ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negative</td>\n",
       "      <td>madshad wow  thats kinda sad then bet it was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'Bens car broke down in the middle of nowhere....</td>\n",
       "      <td>-1</td>\n",
       "      <td>negative</td>\n",
       "      <td>bens car broke down in the middle of nowhere  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  category  \\\n",
       "0  since rahul gandhis only hope bring down naren...        -1   \n",
       "1  modi once called sonia jersey cow rahul her hy...        -1   \n",
       "2  least seven government school teachers have be...        -1   \n",
       "3  '@MadShad31 Wow, thats kinda sad then  Bet it ...        -1   \n",
       "4  'Bens car broke down in the middle of nowhere....        -1   \n",
       "\n",
       "  category_sentiment                                        pre_process  \n",
       "0           negative  since rahul gandhis only hope bring down naren...  \n",
       "1           negative  modi once called sonia jersey cow rahul her hy...  \n",
       "2           negative  least seven government school teachers have be...  \n",
       "3           negative    madshad wow  thats kinda sad then bet it was...  \n",
       "4           negative  bens car broke down in the middle of nowhere  ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f4e7004",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (96792,) (96792,) Test:  ((32265,), (32265,))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train, Y_test = train_test_split(data['pre_process'], data['category'], test_size=0.25, random_state=30)\n",
    "print(\"Train: \",X_train.shape,Y_train.shape,\"Test: \",(X_test.shape,Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ce1235c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF Vectorizer……\n"
     ]
    }
   ],
   "source": [
    "print(\"TFIDF Vectorizer……\")\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer= TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25b1b23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the dimensionality of the input data\n",
    "svd = TruncatedSVD(n_components=2000)\n",
    "X_train = svd.fit_transform(X_train)\n",
    "X_test = svd.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3eac47d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target variable\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(Y_train)\n",
    "y_test = encoder.fit_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fbc3d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the target variable\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "587f157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the deep learning model\n",
    "model = Sequential()\n",
    "model.add(Dense(2000, input_shape=(2000,), activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9262ee0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes in the target variable:  2\n"
     ]
    }
   ],
   "source": [
    "unique_classes = np.unique(y_train)\n",
    "n_classes = len(unique_classes)\n",
    "print(\"Number of classes in the target variable: \", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cba72d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neurons in the last dense layer:  3\n"
     ]
    }
   ],
   "source": [
    "last_layer = model.layers[-1]\n",
    "n_neurons = last_layer.output_shape[-1]\n",
    "print(\"Number of neurons in the last dense layer: \", n_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61009db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "681/681 [==============================] - ETA: 0s - loss: 0.5058 - accuracy: 0.8034"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=128, validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d261b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98537987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acae6a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Negation(sentence):\t\n",
    "    '''\n",
    "    Input: Tokenized sentence (List of words)\n",
    "    Output: Tokenized sentence with negation handled (List of words)\n",
    "    '''\n",
    "    temp = int(0)\n",
    "    for i in range(len(sentence)):\n",
    "        if sentence[i-1] in ['not',\"n't\"]:\n",
    "            antonyms = []\n",
    "            for syn in wordnet.synsets(sentence[i]):\n",
    "                syns = wordnet.synsets(sentence[i])\n",
    "                w1 = syns[0].name()\n",
    "                temp = 0\n",
    "                for l in syn.lemmas():\n",
    "                    if l.antonyms():\n",
    "                        antonyms.append(l.antonyms()[0].name())\n",
    "                max_dissimilarity = 0\n",
    "                for ant in antonyms:\n",
    "                    syns = wordnet.synsets(ant)\n",
    "                    w2 = syns[0].name()\n",
    "                    syns = wordnet.synsets(sentence[i])\n",
    "                    w1 = syns[0].name()\n",
    "                    word1 = wordnet.synset(w1)\n",
    "                    word2 = wordnet.synset(w2)\n",
    "                    if isinstance(word1.wup_similarity(word2), float) or isinstance(word1.wup_similarity(word2), int):\n",
    "                        temp = 1 - word1.wup_similarity(word2)\n",
    "                    if temp>max_dissimilarity:\n",
    "                        max_dissimilarity = temp\n",
    "                        antonym_max = ant\n",
    "                        sentence[i] = antonym_max\n",
    "                        sentence[i-1] = ''\n",
    "    while '' in sentence:\n",
    "        sentence.remove('')\n",
    "    sentence = ' '.join(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c462fba6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Input your own tweet\n",
    "tweet = \"I like apples.\"\n",
    "\n",
    "# Pre-process the tweet\n",
    "tweet = BeautifulSoup(tweet).get_text()\n",
    "tweet = contractions(tweet)\n",
    "tweet = Negation(nltk.word_tokenize(tweet))\n",
    "\n",
    "print(tweet)\n",
    "# Vectorize the tweet using Tf-idf\n",
    "tweet_vector = vectorizer.transform([tweet])\n",
    "tweet_vector = tf.sparse.from_dense(tweet_vector.todense())\n",
    "tweet_vector = tf.sparse.reorder(tweet_vector)\n",
    "# print(tweet_vector.get_shape())\n",
    "tweet_vector = svd.fit_transform(tweet_vector)\n",
    "\n",
    "# Predict the sentiment of the tweet\n",
    "sentiment = model.predict(tweet_vector)\n",
    "\n",
    "# Print the sentiment\n",
    "if sentiment == -1:\n",
    "    print(\"Negative\")\n",
    "elif sentiment == 0:\n",
    "    print(\"Neutral\")\n",
    "else:\n",
    "    print(\"Positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f17e73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickl = {\"vectorizer\": vectorizer,\n",
    "         \"model\": model\n",
    "         }\n",
    "pickle.dump(pickl, open('deep_learning_model'+\".p\", \"wb\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
