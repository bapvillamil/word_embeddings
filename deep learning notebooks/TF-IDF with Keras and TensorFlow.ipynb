{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b730fc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "# nltk.download('punkt')\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50167fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "      <th>category_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  category  \\\n",
       "0  when modi promised “minimum government maximum...        -1   \n",
       "1  talk all the nonsense and continue all the dra...         0   \n",
       "2  what did just say vote for modi  welcome bjp t...         1   \n",
       "3  asking his supporters prefix chowkidar their n...         1   \n",
       "4  answer who among these the most powerful world...         1   \n",
       "\n",
       "  category_sentiment  \n",
       "0           negative  \n",
       "1            neutral  \n",
       "2           positive  \n",
       "3           positive  \n",
       "4           positive  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Twitter.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3095c044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    72254\n",
       " 0    62713\n",
       "-1    43019\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.dropna()\n",
    "df['category'] = df['category'].astype(int)\n",
    "df = df.reset_index(drop=True)\n",
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de8d9e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    72254\n",
       " 0    62713\n",
       "-1    43019\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df=df[df['category']!=0]\n",
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe85e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CPORGALINAS\\AppData\\Local\\Temp\\ipykernel_9012\\490375356.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data=data.append(df[df['category']==0][:43019])\n",
      "C:\\Users\\CPORGALINAS\\AppData\\Local\\Temp\\ipykernel_9012\\490375356.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data=data.append(df[df['category']==1][:43019])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1    43019\n",
       " 0    43019\n",
       " 1    43019\n",
       "Name: category, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "      <th>category_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all the political parties are cheats you call ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the technology shoot down satellite orbit some...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>will ensure family friends relatives vote bein...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unfortunate that names mahatma gandhi nehru an...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>earlier people asked who modi now they know wh...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129052</th>\n",
       "      <td>khan itself enough guarantee below average bra...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129053</th>\n",
       "      <td>well done drdo happy theatre day modi rahul ga...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129054</th>\n",
       "      <td>corruption reduced govt opened bank accounts o...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129055</th>\n",
       "      <td>modi breathes bhupendra chaubhe sir this brill...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129056</th>\n",
       "      <td>thanks weve just dropped our new modi merch pl...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129057 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean_text  category  \\\n",
       "0       all the political parties are cheats you call ...        -1   \n",
       "1       the technology shoot down satellite orbit some...        -1   \n",
       "2       will ensure family friends relatives vote bein...        -1   \n",
       "3       unfortunate that names mahatma gandhi nehru an...        -1   \n",
       "4       earlier people asked who modi now they know wh...        -1   \n",
       "...                                                   ...       ...   \n",
       "129052  khan itself enough guarantee below average bra...         1   \n",
       "129053  well done drdo happy theatre day modi rahul ga...         1   \n",
       "129054  corruption reduced govt opened bank accounts o...         1   \n",
       "129055  modi breathes bhupendra chaubhe sir this brill...         1   \n",
       "129056  thanks weve just dropped our new modi merch pl...         1   \n",
       "\n",
       "       category_sentiment  \n",
       "0                negative  \n",
       "1                negative  \n",
       "2                negative  \n",
       "3                negative  \n",
       "4                negative  \n",
       "...                   ...  \n",
       "129052           positive  \n",
       "129053           positive  \n",
       "129054           positive  \n",
       "129055           positive  \n",
       "129056           positive  \n",
       "\n",
       "[129057 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True) #shuffling of tweets\n",
    "data=df[df['category']==-1][:43019]\n",
    "data=data.append(df[df['category']==0][:43019])\n",
    "data=data.append(df[df['category']==1][:43019])\n",
    "data = data.reset_index(drop=True)\n",
    "display(data['category'].value_counts())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d052fa6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CPORGALINAS\\Documents\\Machine Learning\\Revalida 2\\env\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data['pre_process'] = data['clean_text'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
    "data['pre_process']=data['pre_process'].apply(lambda x: BeautifulSoup(x).get_text())\n",
    "data['pre_process']=data['pre_process'].apply(lambda x: re.sub(r\"http\\S+\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30c1c06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contractions(s):\n",
    "    s = re.sub(r\"won't\", \"will not\",s)\n",
    "    s = re.sub(r\"would't\", \"would not\",s)\n",
    "    s = re.sub(r\"could't\", \"could not\",s)\n",
    "    s = re.sub(r\"\\'d\", \" would\",s)\n",
    "    s = re.sub(r\"can\\'t\", \"can not\",s)\n",
    "    s = re.sub(r\"n\\'t\", \" not\", s)\n",
    "    s= re.sub(r\"\\'re\", \" are\", s)\n",
    "    s = re.sub(r\"\\'s\", \" is\", s)\n",
    "    s = re.sub(r\"\\'ll\", \" will\", s)\n",
    "    s = re.sub(r\"\\'t\", \" not\", s)\n",
    "    s = re.sub(r\"\\'ve\", \" have\", s)\n",
    "    s = re.sub(r\"\\'m\", \" am\", s)\n",
    "    return s\n",
    "data['pre_process']=data['pre_process'].apply(lambda x:contractions(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6f8ffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pre_process']=data['pre_process'].apply(lambda x: \" \".join([re.sub('[^A-Za-z]+','', x) for x in nltk.word_tokenize(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70dac8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "# stop = stopwords.words('english')\n",
    "# data['pre_process']=data['pre_process'].apply(lambda x: \" \".join([x for x in x.split() if x not in stop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b075e5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem import WordNetLemmatizer\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "# data['pre_process']=data['pre_process'].apply(lambda x: \" \".join([lemmatizer.lemmatize(w) for w in nltk.word_tokenize(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4b62ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "      <th>category_sentiment</th>\n",
       "      <th>pre_process</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all the political parties are cheats you call ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negative</td>\n",
       "      <td>all the political parties are cheats you call ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the technology shoot down satellite orbit some...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negative</td>\n",
       "      <td>the technology shoot down satellite orbit some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>will ensure family friends relatives vote bein...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negative</td>\n",
       "      <td>will ensure family friends relatives vote bein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unfortunate that names mahatma gandhi nehru an...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negative</td>\n",
       "      <td>unfortunate that names mahatma gandhi nehru an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>earlier people asked who modi now they know wh...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negative</td>\n",
       "      <td>earlier people asked who modi now they know wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  category  \\\n",
       "0  all the political parties are cheats you call ...        -1   \n",
       "1  the technology shoot down satellite orbit some...        -1   \n",
       "2  will ensure family friends relatives vote bein...        -1   \n",
       "3  unfortunate that names mahatma gandhi nehru an...        -1   \n",
       "4  earlier people asked who modi now they know wh...        -1   \n",
       "\n",
       "  category_sentiment                                        pre_process  \n",
       "0           negative  all the political parties are cheats you call ...  \n",
       "1           negative  the technology shoot down satellite orbit some...  \n",
       "2           negative  will ensure family friends relatives vote bein...  \n",
       "3           negative  unfortunate that names mahatma gandhi nehru an...  \n",
       "4           negative  earlier people asked who modi now they know wh...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f4e7004",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (96792,) (96792,) Test:  ((32265,), (32265,))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train, Y_test = train_test_split(data['pre_process'], data['category'], test_size=0.25, random_state=30)\n",
    "print(\"Train: \",X_train.shape,Y_train.shape,\"Test: \",(X_test.shape,Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ce1235c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF Vectorizer……\n"
     ]
    }
   ],
   "source": [
    "print(\"TFIDF Vectorizer……\")\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer= TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25b1b23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the dimensionality of the input data\n",
    "svd = TruncatedSVD(n_components=2000)\n",
    "X_train = svd.fit_transform(X_train)\n",
    "X_test = svd.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3eac47d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target variable\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(Y_train)\n",
    "y_test = encoder.fit_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fbc3d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the target variable\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "587f157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the deep learning model\n",
    "model = Sequential()\n",
    "model.add(Dense(2000, input_shape=(2000,), activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9262ee0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes in the target variable:  2\n"
     ]
    }
   ],
   "source": [
    "unique_classes = np.unique(y_train)\n",
    "n_classes = len(unique_classes)\n",
    "print(\"Number of classes in the target variable: \", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cba72d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neurons in the last dense layer:  3\n"
     ]
    }
   ],
   "source": [
    "last_layer = model.layers[-1]\n",
    "n_neurons = last_layer.output_shape[-1]\n",
    "print(\"Number of neurons in the last dense layer: \", n_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61009db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "681/681 [==============================] - 53s 76ms/step - loss: 0.5027 - accuracy: 0.8039 - val_loss: 0.4117 - val_accuracy: 0.8497\n",
      "Epoch 2/20\n",
      "681/681 [==============================] - 53s 77ms/step - loss: 0.3008 - accuracy: 0.8940 - val_loss: 0.3837 - val_accuracy: 0.8655\n",
      "Epoch 3/20\n",
      "681/681 [==============================] - 53s 78ms/step - loss: 0.1569 - accuracy: 0.9456 - val_loss: 0.4644 - val_accuracy: 0.8617\n",
      "Epoch 4/20\n",
      "681/681 [==============================] - 52s 76ms/step - loss: 0.0740 - accuracy: 0.9755 - val_loss: 0.5466 - val_accuracy: 0.8638\n",
      "Epoch 5/20\n",
      "681/681 [==============================] - 52s 76ms/step - loss: 0.0486 - accuracy: 0.9839 - val_loss: 0.6367 - val_accuracy: 0.8643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fd2d34cdc0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=128, validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d261b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1009/1009 [==============================] - 8s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98537987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.20%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acae6a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Negation(sentence):\t\n",
    "    '''\n",
    "    Input: Tokenized sentence (List of words)\n",
    "    Output: Tokenized sentence with negation handled (List of words)\n",
    "    '''\n",
    "    temp = int(0)\n",
    "    for i in range(len(sentence)):\n",
    "        if sentence[i-1] in ['not',\"n't\"]:\n",
    "            antonyms = []\n",
    "            for syn in wordnet.synsets(sentence[i]):\n",
    "                syns = wordnet.synsets(sentence[i])\n",
    "                w1 = syns[0].name()\n",
    "                temp = 0\n",
    "                for l in syn.lemmas():\n",
    "                    if l.antonyms():\n",
    "                        antonyms.append(l.antonyms()[0].name())\n",
    "                max_dissimilarity = 0\n",
    "                for ant in antonyms:\n",
    "                    syns = wordnet.synsets(ant)\n",
    "                    w2 = syns[0].name()\n",
    "                    syns = wordnet.synsets(sentence[i])\n",
    "                    w1 = syns[0].name()\n",
    "                    word1 = wordnet.synset(w1)\n",
    "                    word2 = wordnet.synset(w2)\n",
    "                    if isinstance(word1.wup_similarity(word2), float) or isinstance(word1.wup_similarity(word2), int):\n",
    "                        temp = 1 - word1.wup_similarity(word2)\n",
    "                    if temp>max_dissimilarity:\n",
    "                        max_dissimilarity = temp\n",
    "                        antonym_max = ant\n",
    "                        sentence[i] = antonym_max\n",
    "                        sentence[i-1] = ''\n",
    "    while '' in sentence:\n",
    "        sentence.remove('')\n",
    "    sentence = ' '.join(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5dbba116",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like apples .\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got scalar array instead:\narray=SparseTensor(indices=tf.Tensor(\n[[    0  3778]\n [    0 40035]], shape=(2, 2), dtype=int64), values=tf.Tensor([0.93426902 0.35656892], shape=(2,), dtype=float64), dense_shape=tf.Tensor([    1 78207], shape=(2,), dtype=int64)).\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m tweet_vector \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mreorder(tweet_vector)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# print(tweet_vector.get_shape())\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m tweet_vector \u001b[38;5;241m=\u001b[39m \u001b[43msvd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtweet_vector\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Predict the sentiment of the tweet\u001b[39;00m\n\u001b[0;32m     18\u001b[0m sentiment \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(tweet_vector)\n",
      "File \u001b[1;32m~\\Documents\\Machine Learning\\Revalida 2\\env\\lib\\site-packages\\sklearn\\utils\\_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 142\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    147\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    148\u001b[0m         )\n",
      "File \u001b[1;32m~\\Documents\\Machine Learning\\Revalida 2\\env\\lib\\site-packages\\sklearn\\decomposition\\_truncated_svd.py:224\u001b[0m, in \u001b[0;36mTruncatedSVD.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit model to X and perform dimensionality reduction on X.\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124;03m    Reduced version of X. This will always be a dense array.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m--> 224\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m random_state \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marpack\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\Documents\\Machine Learning\\Revalida 2\\env\\lib\\site-packages\\sklearn\\base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 535\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    536\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\Documents\\Machine Learning\\Revalida 2\\env\\lib\\site-packages\\sklearn\\utils\\validation.py:892\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_2d:\n\u001b[0;32m    890\u001b[0m     \u001b[38;5;66;03m# If input is scalar raise error\u001b[39;00m\n\u001b[0;32m    891\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 892\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    893\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got scalar array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    894\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    895\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    896\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    897\u001b[0m         )\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got scalar array instead:\narray=SparseTensor(indices=tf.Tensor(\n[[    0  3778]\n [    0 40035]], shape=(2, 2), dtype=int64), values=tf.Tensor([0.93426902 0.35656892], shape=(2,), dtype=float64), dense_shape=tf.Tensor([    1 78207], shape=(2,), dtype=int64)).\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# Input your own tweet\n",
    "tweet = \"I like apples.\"\n",
    "\n",
    "# Pre-process the tweet\n",
    "tweet = BeautifulSoup(tweet).get_text()\n",
    "tweet = contractions(tweet)\n",
    "tweet = Negation(nltk.word_tokenize(tweet))\n",
    "\n",
    "print(tweet)\n",
    "# Vectorize the tweet using Tf-idf\n",
    "tweet_vector = vectorizer.transform([tweet])\n",
    "tweet_vector = tf.sparse.from_dense(tweet_vector.todense())\n",
    "tweet_vector = tf.sparse.reorder(tweet_vector)\n",
    "# print(tweet_vector.get_shape())\n",
    "tweet_vector = svd.fit_transform(tweet_vector)\n",
    "\n",
    "# Predict the sentiment of the tweet\n",
    "sentiment = model.predict(tweet_vector)\n",
    "\n",
    "# Print the sentiment\n",
    "if sentiment == -1:\n",
    "    print(\"Negative\")\n",
    "elif sentiment == 0:\n",
    "    print(\"Neutral\")\n",
    "else:\n",
    "    print(\"Positive\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
