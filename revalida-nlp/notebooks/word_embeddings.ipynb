{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from copy import deepcopy\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import classification_report\n",
    "nltk.download('stopwords', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "      <th>category_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  category  \\\n",
       "0  when modi promised “minimum government maximum...        -1   \n",
       "1  talk all the nonsense and continue all the dra...         0   \n",
       "2  what did just say vote for modi  welcome bjp t...         1   \n",
       "3  asking his supporters prefix chowkidar their n...         1   \n",
       "4  answer who among these the most powerful world...         1   \n",
       "\n",
       "  category_sentiment  \n",
       "0           negative  \n",
       "1            neutral  \n",
       "2           positive  \n",
       "3           positive  \n",
       "4           positive  "
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Twitter.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    72254\n",
       " 0    62713\n",
       "-1    43019\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df[\"category\"] = df[\"category\"].astype(int)\n",
    "df = df.reset_index(drop=True)\n",
    "df[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    72254\n",
       "-1    43019\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df[\"category\"] != 0]\n",
    "df[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JDEGUZMAN\\AppData\\Local\\Temp\\ipykernel_1300\\1585417336.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(df[df[\"category\"] == 1][:40000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1    40000\n",
       " 1    40000\n",
       "Name: category, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "      <th>category_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>few people india and out india find themself b...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>omar abdullah lashes out modi for ‘destroying’...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'bumped her leg into the bed side and now carr...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>name one institution set modi the institution ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>modi waste well dangerous indias economy secur...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>fear cycle over and greed cycle back funny see...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>attorney nirav modi has been the since january...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>any modi supporter for development finds words...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>and the very same reason fan modi his strategi...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>where she learnt hit out modi govt knowledge p...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              clean_text  category  \\\n",
       "0      few people india and out india find themself b...        -1   \n",
       "1      omar abdullah lashes out modi for ‘destroying’...        -1   \n",
       "2      'bumped her leg into the bed side and now carr...        -1   \n",
       "3      name one institution set modi the institution ...        -1   \n",
       "4      modi waste well dangerous indias economy secur...        -1   \n",
       "...                                                  ...       ...   \n",
       "79995  fear cycle over and greed cycle back funny see...         1   \n",
       "79996  attorney nirav modi has been the since january...         1   \n",
       "79997  any modi supporter for development finds words...         1   \n",
       "79998  and the very same reason fan modi his strategi...         1   \n",
       "79999  where she learnt hit out modi govt knowledge p...         1   \n",
       "\n",
       "      category_sentiment  \n",
       "0               negative  \n",
       "1               negative  \n",
       "2               negative  \n",
       "3               negative  \n",
       "4               negative  \n",
       "...                  ...  \n",
       "79995           positive  \n",
       "79996           positive  \n",
       "79997           positive  \n",
       "79998           positive  \n",
       "79999           positive  \n",
       "\n",
       "[80000 rows x 3 columns]"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True) #shuffling of tweets\n",
    "data = df[df[\"category\"] == -1][:40000]\n",
    "data = data.append(df[df[\"category\"] == 1][:40000])\n",
    "data = data.reset_index(drop=True)\n",
    "display(data[\"category\"].value_counts())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also lets encode 'sentiment' column. 1 for positive and 0 for negative sentiment\n",
    "data[\"category\"] = data[\"category\"].map({-1:0, 1:1}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary to store the words and its corresponding values\n",
    "#convert words to 50 numbers using glove.6B.50d\n",
    "\n",
    "words = dict()\n",
    "\n",
    "def add_to_dict(d, filename):\n",
    "    with open(filename, \"r\", encoding=\"utf8\") as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.split(' ')\n",
    "            \n",
    "            try:\n",
    "                d[line[0]] = np.array(line[1:], dtype=float)\n",
    "            except:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_to_dict(words, \"glove.6B.50d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample tokenize a tweet\n",
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that will replace group words into its simplest form\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def message_to_token_list(s):\n",
    "    tokens = tokenizer.tokenize(s)\n",
    "    lowercased_tokens = [t.lower() for t in tokens]\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(t) for t in lowercased_tokens]\n",
    "    useful_tokens = [t for t in lemmatized_tokens if t in words]\n",
    "    \n",
    "    return useful_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that will replace each words to its corresponding word embedding\n",
    "def message_to_word_vectors(message, word_dict=words):\n",
    "    processed_list_of_tokens = message_to_token_list(message)\n",
    "    \n",
    "    vectors = []\n",
    "    \n",
    "    for token in processed_list_of_tokens:\n",
    "        if token not in word_dict:\n",
    "            continue\n",
    "        \n",
    "        token_vector = word_dict[token]\n",
    "        vectors.append(token_vector)\n",
    "        \n",
    "    return np.array(vectors, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56000, 12000, 12000)"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert dataframe into train and test sets\n",
    "\n",
    "train_df = data.sample(frac=1, random_state=1)\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "split_index_1 = int(len(train_df) * 0.7)\n",
    "split_index_2 = int(len(train_df) * 0.85)\n",
    "\n",
    "train_df, val_df, test_df = train_df[:split_index_1], train_df[split_index_1:split_index_2], train_df[split_index_2:]\n",
    "\n",
    "len(train_df), len(val_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_X_y(dataframe):\n",
    "    y = dataframe[\"category\"].to_numpy().astype(int)\n",
    "    \n",
    "    all_word_vector_sequences = []\n",
    "    \n",
    "    for message in dataframe[\"clean_text\"]:\n",
    "        message_as_vector_seq = message_to_word_vectors(message)\n",
    "        \n",
    "        if message_as_vector_seq.shape[0] == 0: #if there are no usable tokens in the tweet\n",
    "            message_as_vector_seq = np.zeros(shape=(1, 50))\n",
    "            \n",
    "        all_word_vector_sequences.append(message_as_vector_seq)\n",
    "    \n",
    "    return all_word_vector_sequences, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56000 27\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = df_to_X_y(train_df)\n",
    "\n",
    "print(len(X_train), len(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2363., 7380., 9042., 8508., 7867., 7846., 7517., 4577.,  877.,\n",
       "          23.]),\n",
       " array([ 1. ,  5.9, 10.8, 15.7, 20.6, 25.5, 30.4, 35.3, 40.2, 45.1, 50. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#data analysis for sequence lengths (number of terms in the sequence)\n",
    "\n",
    "sequence_lengths = []\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    sequence_lengths.append(len(X_train[i]))\n",
    "    \n",
    "plt.hist(sequence_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    56000.000000\n",
       "mean        21.399661\n",
       "std         10.178850\n",
       "min          1.000000\n",
       "25%         13.000000\n",
       "50%         21.000000\n",
       "75%         30.000000\n",
       "max         50.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max value will give us the maximum number of useful tokens in a single message\n",
    "\n",
    "pd.Series(sequence_lengths).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zero padding\n",
    "\n",
    "def pad_X(X, desired_sequence_length=50):\n",
    "    X_copy = deepcopy(X)\n",
    "    \n",
    "    for i,x in enumerate(X):\n",
    "        x_seq_len = x.shape[0]\n",
    "        sequence_length_difference = desired_sequence_length - x_seq_len\n",
    "        \n",
    "        pad = np.zeros(shape=(sequence_length_difference, 50))\n",
    "        \n",
    "        X_copy[i] = np.concatenate([x, pad])\n",
    "        \n",
    "    return np.array(X_copy).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56000, 50, 50)"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show how many tweets we have and the dimension of each tweet\n",
    "#the dimension of each tweet is in the form (sequences of # of vectors, # of dimensions = 50)\n",
    "\n",
    "X_train = pad_X(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, y_val = df_to_X_y(val_df)\n",
    "X_val = pad_X(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = df_to_X_y(test_df)\n",
    "X_test = pad_X(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([])\n",
    "\n",
    "model.add(layers.Input(shape=(50, 50)))\n",
    "model.add(layers.LSTM(64, return_sequences=True))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.LSTM(64, return_sequences=True))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.LSTM(64, return_sequences=True))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_25 (LSTM)              (None, 50, 64)            29440     \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 50, 64)            0         \n",
      "                                                                 \n",
      " lstm_26 (LSTM)              (None, 50, 64)            33024     \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 50, 64)            0         \n",
      "                                                                 \n",
      " lstm_27 (LSTM)              (None, 50, 64)            33024     \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 50, 64)            0         \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 3200)              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 3201      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,689\n",
      "Trainable params: 98,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = ModelCheckpoint('model/', save_best_only=True)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss = BinaryCrossentropy(),\n",
    "              metrics = ['accuracy', AUC(name='auc')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    28050\n",
       "0    27950\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies = pd.value_counts(train_df[\"category\"])\n",
    "\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2.0035778175313057, 1: 1.9964349376114081}"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 = negative\n",
    "# 1 = positive\n",
    "weights = {0: frequencies.sum() / frequencies[0], 1: frequencies.sum() / frequencies[1]}\n",
    "\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1750/1750 [==============================] - ETA: 0s - loss: 1.2031 - accuracy: 0.6628 - auc: 0.7292"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_25_layer_call_fn, lstm_cell_25_layer_call_and_return_conditional_losses, lstm_cell_26_layer_call_fn, lstm_cell_26_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1750/1750 [==============================] - 287s 162ms/step - loss: 1.2031 - accuracy: 0.6628 - auc: 0.7292 - val_loss: 0.5621 - val_accuracy: 0.6967 - val_auc: 0.7806\n",
      "Epoch 2/20\n",
      "1750/1750 [==============================] - ETA: 0s - loss: 1.1011 - accuracy: 0.7022 - auc: 0.7822"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_25_layer_call_fn, lstm_cell_25_layer_call_and_return_conditional_losses, lstm_cell_26_layer_call_fn, lstm_cell_26_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1750/1750 [==============================] - 492s 281ms/step - loss: 1.1011 - accuracy: 0.7022 - auc: 0.7822 - val_loss: 0.5308 - val_accuracy: 0.7210 - val_auc: 0.8027\n",
      "Epoch 3/20\n",
      "1750/1750 [==============================] - ETA: 0s - loss: 1.0558 - accuracy: 0.7207 - auc: 0.8042"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_25_layer_call_fn, lstm_cell_25_layer_call_and_return_conditional_losses, lstm_cell_26_layer_call_fn, lstm_cell_26_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1750/1750 [==============================] - 407s 233ms/step - loss: 1.0558 - accuracy: 0.7207 - auc: 0.8042 - val_loss: 0.5140 - val_accuracy: 0.7300 - val_auc: 0.8211\n",
      "Epoch 4/20\n",
      "1750/1750 [==============================] - ETA: 0s - loss: 1.0126 - accuracy: 0.7361 - auc: 0.8236"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_25_layer_call_fn, lstm_cell_25_layer_call_and_return_conditional_losses, lstm_cell_26_layer_call_fn, lstm_cell_26_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1750/1750 [==============================] - 460s 263ms/step - loss: 1.0126 - accuracy: 0.7361 - auc: 0.8236 - val_loss: 0.5068 - val_accuracy: 0.7360 - val_auc: 0.8338\n",
      "Epoch 5/20\n",
      "1750/1750 [==============================] - ETA: 0s - loss: 0.9804 - accuracy: 0.7505 - auc: 0.8372"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_25_layer_call_fn, lstm_cell_25_layer_call_and_return_conditional_losses, lstm_cell_26_layer_call_fn, lstm_cell_26_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1750/1750 [==============================] - 388s 222ms/step - loss: 0.9804 - accuracy: 0.7505 - auc: 0.8372 - val_loss: 0.5030 - val_accuracy: 0.7344 - val_auc: 0.8420\n",
      "Epoch 6/20\n",
      "1750/1750 [==============================] - ETA: 0s - loss: 0.9577 - accuracy: 0.7568 - auc: 0.8457"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_25_layer_call_fn, lstm_cell_25_layer_call_and_return_conditional_losses, lstm_cell_26_layer_call_fn, lstm_cell_26_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1750/1750 [==============================] - 620s 354ms/step - loss: 0.9577 - accuracy: 0.7568 - auc: 0.8457 - val_loss: 0.4726 - val_accuracy: 0.7614 - val_auc: 0.8507\n",
      "Epoch 7/20\n",
      "1750/1750 [==============================] - ETA: 0s - loss: 0.9362 - accuracy: 0.7656 - auc: 0.8540"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_25_layer_call_fn, lstm_cell_25_layer_call_and_return_conditional_losses, lstm_cell_26_layer_call_fn, lstm_cell_26_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1750/1750 [==============================] - 930s 531ms/step - loss: 0.9362 - accuracy: 0.7656 - auc: 0.8540 - val_loss: 0.4657 - val_accuracy: 0.7702 - val_auc: 0.8562\n",
      "Epoch 8/20\n",
      "1750/1750 [==============================] - 1149s 656ms/step - loss: 0.9175 - accuracy: 0.7715 - auc: 0.8607 - val_loss: 0.4754 - val_accuracy: 0.7588 - val_auc: 0.8604\n",
      "Epoch 9/20\n",
      "1750/1750 [==============================] - ETA: 0s - loss: 0.8997 - accuracy: 0.7776 - auc: 0.8667"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_25_layer_call_fn, lstm_cell_25_layer_call_and_return_conditional_losses, lstm_cell_26_layer_call_fn, lstm_cell_26_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1750/1750 [==============================] - 490s 280ms/step - loss: 0.8997 - accuracy: 0.7776 - auc: 0.8667 - val_loss: 0.4613 - val_accuracy: 0.7715 - val_auc: 0.8637\n",
      "Epoch 10/20\n",
      "1750/1750 [==============================] - ETA: 0s - loss: 0.8881 - accuracy: 0.7802 - auc: 0.8705"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_25_layer_call_fn, lstm_cell_25_layer_call_and_return_conditional_losses, lstm_cell_26_layer_call_fn, lstm_cell_26_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1750/1750 [==============================] - 529s 302ms/step - loss: 0.8881 - accuracy: 0.7802 - auc: 0.8705 - val_loss: 0.4571 - val_accuracy: 0.7732 - val_auc: 0.8640\n",
      "Epoch 11/20\n",
      "1750/1750 [==============================] - ETA: 0s - loss: 0.8745 - accuracy: 0.7878 - auc: 0.8751"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_25_layer_call_fn, lstm_cell_25_layer_call_and_return_conditional_losses, lstm_cell_26_layer_call_fn, lstm_cell_26_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1750/1750 [==============================] - 645s 369ms/step - loss: 0.8745 - accuracy: 0.7878 - auc: 0.8751 - val_loss: 0.4525 - val_accuracy: 0.7779 - val_auc: 0.8687\n",
      "Epoch 12/20\n",
      "1750/1750 [==============================] - ETA: 0s - loss: 0.8644 - accuracy: 0.7891 - auc: 0.8784"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_25_layer_call_fn, lstm_cell_25_layer_call_and_return_conditional_losses, lstm_cell_26_layer_call_fn, lstm_cell_26_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1750/1750 [==============================] - 561s 321ms/step - loss: 0.8644 - accuracy: 0.7891 - auc: 0.8784 - val_loss: 0.4434 - val_accuracy: 0.7812 - val_auc: 0.8716\n",
      "Epoch 13/20\n",
      "1750/1750 [==============================] - 653s 373ms/step - loss: 0.8492 - accuracy: 0.7956 - auc: 0.8832 - val_loss: 0.4542 - val_accuracy: 0.7795 - val_auc: 0.8749\n",
      "Epoch 14/20\n",
      "1750/1750 [==============================] - ETA: 0s - loss: 0.8411 - accuracy: 0.7965 - auc: 0.8856"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_25_layer_call_fn, lstm_cell_25_layer_call_and_return_conditional_losses, lstm_cell_26_layer_call_fn, lstm_cell_26_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1750/1750 [==============================] - 685s 391ms/step - loss: 0.8411 - accuracy: 0.7965 - auc: 0.8856 - val_loss: 0.4348 - val_accuracy: 0.7918 - val_auc: 0.8783\n",
      "Epoch 15/20\n",
      "1750/1750 [==============================] - ETA: 0s - loss: 0.8304 - accuracy: 0.8027 - auc: 0.8889"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_25_layer_call_fn, lstm_cell_25_layer_call_and_return_conditional_losses, lstm_cell_26_layer_call_fn, lstm_cell_26_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1750/1750 [==============================] - 570s 326ms/step - loss: 0.8304 - accuracy: 0.8027 - auc: 0.8889 - val_loss: 0.4293 - val_accuracy: 0.7920 - val_auc: 0.8804\n",
      "Epoch 16/20\n",
      "1750/1750 [==============================] - 664s 380ms/step - loss: 0.8203 - accuracy: 0.8053 - auc: 0.8919 - val_loss: 0.4376 - val_accuracy: 0.7893 - val_auc: 0.8793\n",
      "Epoch 17/20\n",
      "1750/1750 [==============================] - 652s 372ms/step - loss: 0.8097 - accuracy: 0.8065 - auc: 0.8949 - val_loss: 0.4312 - val_accuracy: 0.7921 - val_auc: 0.8809\n",
      "Epoch 18/20\n",
      "1750/1750 [==============================] - 693s 396ms/step - loss: 0.8028 - accuracy: 0.8079 - auc: 0.8967 - val_loss: 0.4294 - val_accuracy: 0.7921 - val_auc: 0.8834\n",
      "Epoch 19/20\n",
      "1750/1750 [==============================] - ETA: 0s - loss: 0.7924 - accuracy: 0.8116 - auc: 0.8997"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_25_layer_call_fn, lstm_cell_25_layer_call_and_return_conditional_losses, lstm_cell_26_layer_call_fn, lstm_cell_26_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1750/1750 [==============================] - 661s 378ms/step - loss: 0.7924 - accuracy: 0.8116 - auc: 0.8997 - val_loss: 0.4280 - val_accuracy: 0.7924 - val_auc: 0.8855\n",
      "Epoch 20/20\n",
      "1750/1750 [==============================] - ETA: 0s - loss: 0.7857 - accuracy: 0.8145 - auc: 0.9014"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_25_layer_call_fn, lstm_cell_25_layer_call_and_return_conditional_losses, lstm_cell_26_layer_call_fn, lstm_cell_26_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1750/1750 [==============================] - 1047s 598ms/step - loss: 0.7857 - accuracy: 0.8145 - auc: 0.9014 - val_loss: 0.4228 - val_accuracy: 0.7958 - val_auc: 0.8874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dbc70733d0>"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, callbacks=[cp], class_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = load_model('model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 59s 153ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80      6040\n",
      "           1       0.82      0.75      0.78      5960\n",
      "\n",
      "    accuracy                           0.79     12000\n",
      "   macro avg       0.79      0.79      0.79     12000\n",
      "weighted avg       0.79      0.79      0.79     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions = (best_model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "print(classification_report(y_test, test_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (tags/v3.9.12:b28265d, Mar 23 2022, 23:52:46) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "193895ae6b4eabe17df01151f277708f49eda3a170b6515034f559d78d30fa73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
