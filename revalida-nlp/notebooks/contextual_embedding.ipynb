{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bvsnynbvoBB"
      },
      "source": [
        "# **Sentiment Analysis using Contextual Embedding**\n",
        "\n",
        "### **BERT** stands for *Bidirectional Encoder Representations from Transformers*. It is a language model which looks at both left and right context when predicting current word. This is also called **Masked Language Modelling** (MLM). Additionally, BERT also use *\"next sentence prediction\"* task in addition to MLM during pre-training.\n",
        "\n",
        "Proper language representation is key for general-purpose language understanding by machines. Context-free models such as **word2vec** or **GloVe** generate a single word embedding representation for each word in the vocabulary. For example, the word *\"bank\"* would have the same representation in *\"bank deposit\"* and in *\"riverbank\"*. Contextual models instead generate a representation of each word that is based on the other words in the sentence. BERT, as a contextual model, captures these relationships in a bidirectional way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yG1Puvjkx6mS"
      },
      "source": [
        "## 1. Importing the Required Libraries and Reading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygIht5aC6-vj",
        "outputId": "8d8f4c77-70b9-4ae7-c616-3398741b5273"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: contractions in /usr/local/lib/python3.8/dist-packages (0.1.73)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.8/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.8/dist-packages (from textsearch>=0.0.21->contractions) (0.3.1)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.8/dist-packages (from textsearch>=0.0.21->contractions) (2.0.0)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet') \n",
        "nltk.download('punkt')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "!pip install -qq transformers\n",
        "import transformers\n",
        "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
        "\n",
        "!pip install contractions\n",
        "import contractions\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "QpGZ0Awt6-vl",
        "outputId": "559f699c-408e-4b49-da29-a49d6239b7a7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ae4bf412-30e5-4139-9244-85a9261ca339\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "      <th>category</th>\n",
              "      <th>category_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i am not happy</td>\n",
              "      <td>-1</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i am not sad</td>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i'm fine</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>when modi promised “minimum government maximum...</td>\n",
              "      <td>-1</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>talk all the nonsense and continue all the dra...</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177971</th>\n",
              "      <td>'I'm not satisfied with The Hills finale.  gon...</td>\n",
              "      <td>-1</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177972</th>\n",
              "      <td>this sucks</td>\n",
              "      <td>-1</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177973</th>\n",
              "      <td>this is bad</td>\n",
              "      <td>-1</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177974</th>\n",
              "      <td>I am not okay with this</td>\n",
              "      <td>-1</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177975</th>\n",
              "      <td>this stinks</td>\n",
              "      <td>-1</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>177976 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae4bf412-30e5-4139-9244-85a9261ca339')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ae4bf412-30e5-4139-9244-85a9261ca339 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ae4bf412-30e5-4139-9244-85a9261ca339');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               clean_text  category  \\\n",
              "0                                          i am not happy        -1   \n",
              "1                                            i am not sad         1   \n",
              "2                                                i'm fine         0   \n",
              "3       when modi promised “minimum government maximum...        -1   \n",
              "4       talk all the nonsense and continue all the dra...         0   \n",
              "...                                                   ...       ...   \n",
              "177971  'I'm not satisfied with The Hills finale.  gon...        -1   \n",
              "177972                                         this sucks        -1   \n",
              "177973                                        this is bad        -1   \n",
              "177974                            I am not okay with this        -1   \n",
              "177975                                        this stinks        -1   \n",
              "\n",
              "       category_sentiment  \n",
              "0                negative  \n",
              "1                positive  \n",
              "2                 neutral  \n",
              "3                negative  \n",
              "4                 neutral  \n",
              "...                   ...  \n",
              "177971           negative  \n",
              "177972           negative  \n",
              "177973           negative  \n",
              "177974           negative  \n",
              "177975           negative  \n",
              "\n",
              "[177976 rows x 3 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"Twitter.csv\")\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3duZXnLyd66"
      },
      "source": [
        "## 2. Checking Class Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKVxd9Dp6-vl",
        "outputId": "9491bc42-5cb5-418d-cb45-5349b480b9b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "category_sentiment\n",
              "positive              72250\n",
              "neutral               62712\n",
              "negative              43014\n",
              "dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.iloc[:, -1:].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "fxHCJ5H-jIRL",
        "outputId": "836406c7-e54a-4137-ad5f-577ce24a6af9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-1    35000\n",
              " 1    35000\n",
              " 0    35000\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7ad140e7-b71e-4117-967d-4f60138debc6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "      <th>category</th>\n",
              "      <th>category_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>modi govt took credit for valour armed forces ...</td>\n",
              "      <td>-1</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>opposition saying modi shouldn’ take credit dr...</td>\n",
              "      <td>-1</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>thats the difference between average citizen a...</td>\n",
              "      <td>-1</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>big twist case prosecution argues why bail sho...</td>\n",
              "      <td>-1</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dear modi govt you believe national interest t...</td>\n",
              "      <td>-1</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104995</th>\n",
              "      <td>this man consumed much blind hatred modi their...</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104996</th>\n",
              "      <td>modi said centre and state governments are wor...</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104997</th>\n",
              "      <td>blow modi</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104998</th>\n",
              "      <td>modi must sent back now otherwise india peril</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104999</th>\n",
              "      <td>for air strikes credit must not given govt day...</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>105000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ad140e7-b71e-4117-967d-4f60138debc6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7ad140e7-b71e-4117-967d-4f60138debc6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7ad140e7-b71e-4117-967d-4f60138debc6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               clean_text  category  \\\n",
              "0       modi govt took credit for valour armed forces ...        -1   \n",
              "1       opposition saying modi shouldn’ take credit dr...        -1   \n",
              "2       thats the difference between average citizen a...        -1   \n",
              "3       big twist case prosecution argues why bail sho...        -1   \n",
              "4       dear modi govt you believe national interest t...        -1   \n",
              "...                                                   ...       ...   \n",
              "104995  this man consumed much blind hatred modi their...         0   \n",
              "104996  modi said centre and state governments are wor...         0   \n",
              "104997                                         blow modi          0   \n",
              "104998     modi must sent back now otherwise india peril          0   \n",
              "104999  for air strikes credit must not given govt day...         0   \n",
              "\n",
              "       category_sentiment  \n",
              "0                negative  \n",
              "1                negative  \n",
              "2                negative  \n",
              "3                negative  \n",
              "4                negative  \n",
              "...                   ...  \n",
              "104995            neutral  \n",
              "104996            neutral  \n",
              "104997            neutral  \n",
              "104998            neutral  \n",
              "104999            neutral  \n",
              "\n",
              "[105000 rows x 3 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.sample(frac = 1).reset_index(drop = True) # Shuffling of Tweets\n",
        "df_new = df[df[\"category\"] == -1][:40000]\n",
        "df_new = df_new.append(df[df[\"category\"] == 1][:40000])\n",
        "df_new = df_new.append(df[df[\"category\"] == 0][:40000])\n",
        "df_new = df_new.reset_index(drop = True)\n",
        "\n",
        "display(df_new[\"category\"].value_counts())\n",
        "df_new"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pmq-uDhv3tNk"
      },
      "source": [
        "## 3. Creating a Function for Text Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "q7sqcSgX6-vl"
      },
      "outputs": [],
      "source": [
        "def text_transformation(text):\n",
        "    text = \" \".join(x.lower() for x in str(text).split())                             # Converting Text to Lowercase\n",
        "    text = contractions.fix(text)                                                     # Fixes Contractions such as (\"you're\" to \"you are\" etc.)\n",
        "    text = \" \".join([re.sub(\"[^A-Za-z]+\", \"\", x) for x in nltk.word_tokenize(text)])  # Removal of Punctuation, Numbers, and Special Characters                                                                      \n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_Y9ugGba6-vm"
      },
      "outputs": [],
      "source": [
        "df_new[\"category\"] = df_new[\"category\"].map({-1:0, 0:1, 1:2})    # Mapping '0' - negative, '1' - neutral, '2' - positive "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xpWu01O4JSG"
      },
      "source": [
        "## 4. Checking for CUDA Availability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GgYws6m6-vm",
        "outputId": "887a050c-93ef-4015-99b2-0c040c1ce994"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device Name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"There are {torch.cuda.device_count()} GPU(s) available.\")\n",
        "    print(\"Device Name:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print(\"No GPU available, using the CPU instead.\")\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "torch.cuda.empty_cache()  # Emptying the cache to prevent out of memory "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsVN8I9_44xM"
      },
      "source": [
        "## 5. Applying Text Transformation to the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sn2JVpN-6-vm",
        "outputId": "0f543c31-621b-4f9d-bfce-3e1e5efad2f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Text:  modi govt took credit for valour armed forces failed ensure their safety tdp \n",
            "Processed Text:  modi govt took credit for valour armed forces failed ensure their safety tdp\n"
          ]
        }
      ],
      "source": [
        "print(\"Original Text: \", df_new[\"clean_text\"].iloc[0])\n",
        "print(\"Processed Text: \", text_transformation(df_new[\"clean_text\"].iloc[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "QTJlFguJ6-vm",
        "outputId": "40c21fdb-b08f-413c-dac7-f5e5a6d08494"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-54acef8b-af92-4812-adb5-64f06e0b1845\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "      <th>category</th>\n",
              "      <th>category_sentiment</th>\n",
              "      <th>processed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>modi govt took credit for valour armed forces ...</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "      <td>modi govt took credit for valour armed forces ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>opposition saying modi shouldn’ take credit dr...</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "      <td>opposition saying modi shouldn  take credit dr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>thats the difference between average citizen a...</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "      <td>that is the difference between average citizen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>big twist case prosecution argues why bail sho...</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "      <td>big twist case prosecution argues why bail sho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dear modi govt you believe national interest t...</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "      <td>dear modi govt you believe national interest t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104995</th>\n",
              "      <td>this man consumed much blind hatred modi their...</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>this man consumed much blind hatred modi their...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104996</th>\n",
              "      <td>modi said centre and state governments are wor...</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>modi said centre and state governments are wor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104997</th>\n",
              "      <td>blow modi</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>blow modi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104998</th>\n",
              "      <td>modi must sent back now otherwise india peril</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>modi must sent back now otherwise india peril</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104999</th>\n",
              "      <td>for air strikes credit must not given govt day...</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>for air strikes credit must not given govt day...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>105000 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54acef8b-af92-4812-adb5-64f06e0b1845')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-54acef8b-af92-4812-adb5-64f06e0b1845 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-54acef8b-af92-4812-adb5-64f06e0b1845');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               clean_text  category  \\\n",
              "0       modi govt took credit for valour armed forces ...         0   \n",
              "1       opposition saying modi shouldn’ take credit dr...         0   \n",
              "2       thats the difference between average citizen a...         0   \n",
              "3       big twist case prosecution argues why bail sho...         0   \n",
              "4       dear modi govt you believe national interest t...         0   \n",
              "...                                                   ...       ...   \n",
              "104995  this man consumed much blind hatred modi their...         1   \n",
              "104996  modi said centre and state governments are wor...         1   \n",
              "104997                                         blow modi          1   \n",
              "104998     modi must sent back now otherwise india peril          1   \n",
              "104999  for air strikes credit must not given govt day...         1   \n",
              "\n",
              "       category_sentiment                                     processed_text  \n",
              "0                negative  modi govt took credit for valour armed forces ...  \n",
              "1                negative  opposition saying modi shouldn  take credit dr...  \n",
              "2                negative  that is the difference between average citizen...  \n",
              "3                negative  big twist case prosecution argues why bail sho...  \n",
              "4                negative  dear modi govt you believe national interest t...  \n",
              "...                   ...                                                ...  \n",
              "104995            neutral  this man consumed much blind hatred modi their...  \n",
              "104996            neutral  modi said centre and state governments are wor...  \n",
              "104997            neutral                                          blow modi  \n",
              "104998            neutral      modi must sent back now otherwise india peril  \n",
              "104999            neutral  for air strikes credit must not given govt day...  \n",
              "\n",
              "[105000 rows x 4 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_new[\"processed_text\"] = df_new[\"clean_text\"].apply(text_transformation)\n",
        "df_new"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtOkNQ6h5_c6"
      },
      "source": [
        "## 6. Importing the BERT Pre-Trained Model and Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "s73GJZyN6-vn"
      },
      "outputs": [],
      "source": [
        "PRE_TRAINED_MODEL_NAME = \"distilbert-base-uncased\"                       # Importing the BERT-based Pre-Trained Model               \n",
        "tokenizer = DistilBertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)  # Loading the Pre-Trained BertTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kI01tRQ6ZR1"
      },
      "source": [
        "## 7. Tokenization Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjFBGN7t6-vn",
        "outputId": "4d93031b-11b1-4d98-9a74-ffd514a1df8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: modi govt took credit for valour armed forces failed ensure their safety tdp\n",
            "Tokens: ['mod', '##i', 'govt', 'took', 'credit', 'for', 'val', '##our', 'armed', 'forces', 'failed', 'ensure', 'their', 'safety', 'td', '##p']\n",
            "Token IDs: [16913, 2072, 22410, 2165, 4923, 2005, 11748, 8162, 4273, 2749, 3478, 5676, 2037, 3808, 14595, 2361]\n"
          ]
        }
      ],
      "source": [
        "sample_text = text_transformation(df_new[\"processed_text\"][0])  # Get a sample text from the dataset\n",
        "\n",
        "tokens = tokenizer.tokenize(sample_text)            # This will convert a sentence to a list of words\n",
        "token_ids = tokenizer.convert_tokens_to_ids(tokens) # This will convert the list of words to a list of numbers based on tokenizer\n",
        "\n",
        "print(f\"Sentence: {sample_text}\")\n",
        "print(f\"Tokens: {tokens}\")\n",
        "print(f\"Token IDs: {token_ids}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIA1EyYE71MT"
      },
      "source": [
        "## Special Tokens\n",
        "\n",
        "**[SEP]** - marker for ending of a sentence </br>\n",
        "**[CLS]** - add this token to the start of each sentence, so BERT knows it's a classification </br>\n",
        "**[PAD]** - adds padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uv3p3-1a6-vn",
        "outputId": "98aafa41-ec60-4e46-a8ce-e9516d740af6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "64\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([  101, 16913,  2072, 22410,  2165,  4923,  2005, 11748,  8162,  4273,\n",
              "         2749,  3478,  5676,  2037,  3808, 14595,  2361,   102,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "    sample_text,                    # Sample Text\n",
        "    max_length = 64,                # Max Length of the Sentence\n",
        "    truncation = True,              # Truncate to a maximum length specified with argument max_length\n",
        "    add_special_tokens = True,      # Add '[CLS]', [PAD] and '[SEP]'\n",
        "    return_token_type_ids = False,  # This case deals with only one sentence as opposed to two sentences in single training\n",
        "    padding = \"max_length\",         # Pad to longest sequence as defined by max_length\n",
        "    return_attention_mask = True,   # Attention mask indicated to the model which tokens should be attended to, and which should not\n",
        "    return_tensors = \"pt\",            # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "# Encoding which corresponds to the weight of each word\n",
        "print(len(encoding[\"input_ids\"][0]))\n",
        "encoding[\"input_ids\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEMwAWA7CGJE",
        "outputId": "edc3f627-2b5d-4e60-ec56-49782c4fb940"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "64\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Attention Mask also has same length with Encoding\n",
        "print(len(encoding[\"attention_mask\"][0]))\n",
        "encoding[\"attention_mask\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qx6sOvDG9pbt"
      },
      "source": [
        "## Creating a Class Implemeting the Processes Above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GELdmDzy6-vo"
      },
      "outputs": [],
      "source": [
        "max_len = 64\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(self, text, category, tokenizer, max_len):\n",
        "        self.text = text\n",
        "        self.category = category\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        text = str(self.text[item])\n",
        "        category = self.category[item]\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens = True,\n",
        "            max_length = self.max_len,\n",
        "            truncation = True,\n",
        "            return_token_type_ids = False,\n",
        "            padding = \"max_length\",\n",
        "            return_attention_mask = True,\n",
        "            return_tensors = \"pt\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"text\": text,\n",
        "            \"input_ids\": encoding[\"input_ids\"].flatten(),         \n",
        "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
        "            \"category\": torch.tensor(category, dtype = torch.long)\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfqF4q1e-cra"
      },
      "source": [
        "## 8. Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGFXtpAM6-vo",
        "outputId": "c0506716-b36f-4f77-b643-3c071d8d1e10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(84000, 2) (21000, 2)\n"
          ]
        }
      ],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(df_new[\"processed_text\"], df_new[\"category\"], test_size = 0.20, random_state = 1, stratify=df_new[\"category_sentiment\"])\n",
        "\n",
        "df_train = pd.concat([pd.DataFrame({\"processed_text\": x_train.values}), pd.DataFrame({\"category\": y_train.values})], axis = 1)\n",
        "df_test = pd.concat([pd.DataFrame({\"processed_text\": x_test.values}), pd.DataFrame({\"category\": y_test.values})], axis = 1)\n",
        "\n",
        "\n",
        "print(df_train.shape, df_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdesfJ-iDOyX"
      },
      "source": [
        "## 9. Creating the Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iyXesar6-vo",
        "outputId": "c7a00fe1-98cf-4879-a764-0023d5bda6cd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "\n",
        "    ds = Dataset(\n",
        "        text = df.processed_text.to_numpy(),\n",
        "        category = df.category.to_numpy(),\n",
        "        tokenizer = tokenizer,\n",
        "        max_len = max_len\n",
        "    )\n",
        "  \n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size = batch_size,\n",
        "        num_workers = 4  # Tells the data loader how many sub-processes to use for data loading\n",
        "    )\n",
        "\n",
        "\n",
        "batch_size = 32     # Bert recommendation\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, max_len, batch_size)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, max_len, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_X3WdQk9Fp-",
        "outputId": "fcb30574-7720-4b1b-dca8-1626d464f4a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 64])\n",
            "torch.Size([32, 64])\n"
          ]
        }
      ],
      "source": [
        "data = next(iter(train_data_loader))\n",
        "\n",
        "print(data[\"input_ids\"].shape)\n",
        "print(data[\"attention_mask\"].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZd41O2HDTNC"
      },
      "source": [
        "## 10. Building the Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Adb9QOIa6-vo",
        "outputId": "e0f9c81c-9421-4a6d-b528-946bb3611eaf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = DistilBertForSequenceClassification.from_pretrained(PRE_TRAINED_MODEL_NAME, num_labels = 3, return_dict = False)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "GK3QHu556-vp"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr = 5e-4)\n",
        "total_steps = len(train_data_loader) * EPOCHS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "W5Rm0ISN6-vp"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, data_loader, optimizer, device, n_examples):\n",
        "\n",
        "    model = model.train()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    for d in data_loader:\n",
        "        input_ids = d[\"input_ids\"].to(device)\n",
        "        attention_mask = d[\"attention_mask\"].to(device)\n",
        "        targets = d[\"category\"].to(device)\n",
        "\n",
        "        loss, logits = model(\n",
        "          input_ids = input_ids,\n",
        "          attention_mask = attention_mask,\n",
        "          labels = targets\n",
        "        )\n",
        "        \n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = targets.cpu().numpy()\n",
        "\n",
        "        prediction = np.argmax(logits).flatten()\n",
        "        target = label_ids.flatten()\n",
        "\n",
        "        correct_predictions += np.sum(prediction == target)\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        loss.backward()             # Performs backpropagation (computes derivates of loss w.r.t to parameters)\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm = 1.0)  # Clipping gradients so they dont explode\n",
        "        optimizer.step()            # Makes the optimizer iterate over all parameters and update their gradient values\n",
        "        optimizer.zero_grad()       # Clears old gradients from last step\n",
        "\n",
        "    return correct_predictions / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "eq1kxw0R6-vp"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, data_loader, device, n_examples):\n",
        "  \n",
        "    model = model.eval()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for d in data_loader:\n",
        "            input_ids = d[\"input_ids\"].to(device)\n",
        "            attention_mask = d[\"attention_mask\"].to(device)\n",
        "            targets = d[\"category\"].to(device)\n",
        "\n",
        "            loss, logits = model(\n",
        "              input_ids = input_ids,\n",
        "              attention_mask = attention_mask,\n",
        "              labels = targets\n",
        "            )\n",
        "\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = targets.cpu().numpy()\n",
        "\n",
        "            prediction = np.argmax(logits).flatten()\n",
        "            target = label_ids.flatten()\n",
        "\n",
        "            correct_predictions += np.sum(prediction == target)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "    return correct_predictions / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyIoKZcb6-vp",
        "outputId": "a56d89da-62da-43d8-823f-85a1ebfe34d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 / 10\n",
            "----------\n",
            "Train Loss 1.0995535072145008 Accuracy 0.16016666666666668\n",
            "Test Loss 1.0986175219580825 Accuracy 0.3333333333333333\n",
            "\n",
            "Epoch 2 / 10\n",
            "----------\n",
            "Train Loss 1.0992739740553357 Accuracy 0.13238095238095238\n",
            "Test Loss 1.0987241857853836 Accuracy 0.037476190476190475\n",
            "\n",
            "Epoch 3 / 10\n",
            "----------\n",
            "Train Loss 1.0989082431339083 Accuracy 0.01217857142857143\n",
            "Test Loss 1.0986224672384277 Accuracy 0.026333333333333334\n",
            "\n",
            "Epoch 4 / 10\n",
            "----------\n",
            "Train Loss 1.0987532854988462 Accuracy 0.012142857142857143\n",
            "Test Loss 1.0986170273393256 Accuracy 0.03395238095238095\n",
            "\n",
            "Epoch 5 / 10\n",
            "----------\n",
            "Train Loss 1.0988344021751768 Accuracy 0.012047619047619048\n",
            "Test Loss 1.098815594271075 Accuracy 0.0880952380952381\n",
            "\n",
            "Epoch 6 / 10\n",
            "----------\n",
            "Train Loss 1.0932912505921863 Accuracy 0.010928571428571428\n",
            "Test Loss 1.1362453171107323 Accuracy 0.05333333333333334\n",
            "\n",
            "Epoch 7 / 10\n",
            "----------\n",
            "Train Loss 1.0862716469991776 Accuracy 0.01138095238095238\n",
            "Test Loss 1.1785727146916556 Accuracy 0.12385714285714286\n",
            "\n",
            "Epoch 8 / 10\n",
            "----------\n",
            "Train Loss 1.0829077526274182 Accuracy 0.009226190476190476\n",
            "Test Loss 1.1862060462140238 Accuracy 0.31852380952380954\n",
            "\n",
            "Epoch 9 / 10\n",
            "----------\n",
            "Train Loss 1.0802530598640443 Accuracy 0.010404761904761905\n",
            "Test Loss 1.1565244567993025 Accuracy 0.051666666666666666\n",
            "\n",
            "Epoch 10 / 10\n",
            "----------\n",
            "Train Loss 1.081943053949447 Accuracy 0.009761904761904762\n",
            "Test Loss 1.216866281116027 Accuracy 0.05295238095238095\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Used Accuracy as Performance Metric\n",
        "\n",
        "best_acc = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    print(f\"Epoch {epoch + 1} / {EPOCHS}\")\n",
        "    print(\"-\" * 10)\n",
        "\n",
        "    train_acc, train_loss = train_epoch(model, train_data_loader, optimizer, device, len(df_train))\n",
        "\n",
        "    print(f\"Train Loss {train_loss} Accuracy {train_acc}\")\n",
        "\n",
        "    test_acc, test_loss = eval_model(model, test_data_loader, device, len(df_test))\n",
        "\n",
        "    print(f\"Test Loss {test_loss} Accuracy {test_acc}\")\n",
        "    print()\n",
        "\n",
        "    if test_acc > best_acc:\n",
        "      torch.save(model.state_dict(), \"contextual_embedding_model.pth\")\n",
        "      best_acc = test_acc\n",
        "\n",
        "# Storing the State of Best Model Indicated by Highest Validation Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "dSOdqa5eJvOH"
      },
      "outputs": [],
      "source": [
        "# Load the Trained Model\n",
        "\n",
        "path1 = \"/content/contextual_embedding_model.pth\"\n",
        "\n",
        "model.load_state_dict(torch.load(path1))\n",
        "\n",
        "model = model.to(device)    # Moving Model to Device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWZSVnTTJ6Tk",
        "outputId": "98172783-410d-4435-8305-9889cd6fde7e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.3333333333333333"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_acc, _ = eval_model(model, test_data_loader, device, len(df_test))\n",
        "test_acc.item()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12 (tags/v3.9.12:b28265d, Mar 23 2022, 23:52:46) [MSC v.1929 64 bit (AMD64)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "70f9019b7ea4305493975d3f8c57c4982a33c13e123e9c3379d7ec4fac4fcd77"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
